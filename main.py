import os
import shutil
import cv2
import tkinter as tk
from tkinter import messagebox
from PIL import Image, ImageTk
from ultralytics import YOLO
from tqdm import tqdm
import sqlite3
import json
import hashlib
from datetime import datetime
from dataclasses import dataclass
from typing import Optional, List, Tuple

from dataclasses import dataclass
from typing import Optional, List, Tuple

# === Data Classes for Simplified Function Signatures ===

@dataclass
class FileInfo:
    """Container for file processing information."""
    relative_path: str
    absolute_path: str
    size: int
    mtime: float
    width: int = 0
    height: int = 0

@dataclass
class DetectionResult:
    """Container for YOLO detection results."""
    boxes: Optional[object] = None
    labels: Optional[object] = None
    confidences: Optional[object] = None
    has_error: bool = False
    discard_reasons: List[str] = None
    needs_manual_decision: bool = False
    
    def __post_init__(self):
        if self.discard_reasons is None:
            self.discard_reasons = []

@dataclass 
class ProcessingStats:
    """Container for processing statistics."""
    total_files: int = 0
    processed_files: int = 0
    cached_files: int = 0
    auto_sorted: int = 0
    manual_decisions: int = 0
    manual_sorted: int = 0
    kept_files: int = 0
    errors: int = 0

@dataclass
class ProcessingContext:
    """Container for processing context and configuration."""
    source_folder: str
    target_folder: str
    db_path: str
    stats: ProcessingStats
    pbar: object

# === Konfiguration ===
CONFIG = {
    'source_folder': "~/wallpaper/gallery-dl/",
    'target_folder': "~/wallpaper/discarded/",  # Ordner f√ºr unerw√ºnschte Bilder
    'model_path': "yolov8s.pt",  # vortrainiertes YOLOv8-Modell
    'device': 'cpu',
    'target_classes': ['car', 'person', 'motorcycle'],  # Zielklassen: Autos und erkennbare Personen
    'large_area_threshold': 200000,  # Mindestfl√§che f√ºr gro√üe Objekte (‚â•200k + hohe Confidence = aussortieren)
    'small_area_threshold': 50000,  # Maximale Fl√§che f√ºr kleine Objekte (‚â§75k = automatisch behalten)
    'min_confidence_threshold': 0.25,  # Mindest-Confidence-Score (darunter wird ignoriert)
    'max_confidence_threshold': 0.7,  # Maximaler Confidence-Schwelle (‚â•0.7 bei gro√üen Objekten = aussortieren)
    'min_resolution': [1920, 1080],  # Mindestaufl√∂sung [Breite, H√∂he] f√ºr Wallpaper
    'aspect_ratio_tolerance': 0.1,  # Toleranz f√ºr Seitenverh√§ltnis-Abweichung
    'supported_extensions': (".jpg", ".jpeg", ".png", ".bmp", ".tiff", ".webp")
}

# Extrahiere Konfigurationswerte f√ºr Kompatibilit√§t
source_folder = os.path.expanduser(CONFIG['source_folder'])
target_folder = os.path.expanduser(CONFIG['target_folder'])
model_path = CONFIG['model_path']
device = CONFIG['device']
target_classes = CONFIG['target_classes']
large_area_threshold = CONFIG['large_area_threshold']
small_area_threshold = CONFIG['small_area_threshold']
min_confidence_threshold = CONFIG['min_confidence_threshold']
max_confidence_threshold = CONFIG['max_confidence_threshold']
min_resolution = CONFIG['min_resolution']
target_aspect_ratio = min_resolution[0] / min_resolution[1]  # Berechne aus der Mindestaufl√∂sung
aspect_ratio_tolerance = CONFIG['aspect_ratio_tolerance']

# === Modell laden ===
model = YOLO(model_path)

# === Database Functions ===
class DatabaseManager:
    """Manages all database operations for caching processed files."""
    
    def __init__(self, source_folder: str):
        self.source_folder = source_folder
        self.db_path = os.path.join(source_folder, '.image_filter_cache.db')
    
    def get_config_hash(self) -> str:
        """
        Erstellt einen MD5-Hash der aktuellen Konfiguration f√ºr Cache-Invalidierung.
        
        Returns:
            str: MD5-Hash der serialisierten CONFIG als Hexadezimal-String
        """
        config_str = json.dumps(CONFIG, sort_keys=True)
        return hashlib.md5(config_str.encode()).hexdigest()

    def init_database(self) -> str:
        """
        Initialisiert die SQLite-Datenbank im Source-Ordner mit den erforderlichen Tabellen.
        
        Erstellt Tabellen f√ºr Konfiguration und verarbeitete Dateien. Pr√ºft ob die aktuelle
        Konfiguration bereits existiert und setzt die Datenbank zur√ºck falls sich die
        Konfiguration ge√§ndert hat.
        
        Returns:
            str: Absoluter Pfad zur Datenbankdatei
        """
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Tabelle f√ºr Konfiguration
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS config (
                    id INTEGER PRIMARY KEY,
                    config_hash TEXT UNIQUE,
                    config_data TEXT,
                    created_at TIMESTAMP
                )
            ''')
            
            # Tabelle f√ºr verarbeitete Dateien
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS processed_files (
                    id INTEGER PRIMARY KEY,
                    file_path TEXT UNIQUE,
                    config_hash TEXT,
                    file_size INTEGER,
                    file_mtime REAL,
                    decision TEXT,
                    discard_reasons TEXT,
                    created_at TIMESTAMP,
                    FOREIGN KEY (config_hash) REFERENCES config (config_hash)
                )
            ''')
            
            conn.commit()
            
            # Pr√ºfe ob aktuelle Konfiguration existiert
            current_hash = self.get_config_hash()
            cursor.execute('SELECT config_hash FROM config WHERE config_hash = ?', (current_hash,))
            
            if not cursor.fetchone():
                # Neue Konfiguration - l√∂sche alte Daten
                cursor.execute('DELETE FROM processed_files')
                cursor.execute('DELETE FROM config')
                
                # F√ºge neue Konfiguration hinzu
                cursor.execute('''
                    INSERT INTO config (config_hash, config_data, created_at)
                    VALUES (?, ?, ?)
                ''', (current_hash, json.dumps(CONFIG, indent=2), datetime.now()))
                
                conn.commit()
                print("üóÑÔ∏è Neue Konfiguration erkannt - Datenbank zur√ºckgesetzt")
            else:
                print("üóÑÔ∏è Bestehende Konfiguration gefunden - verwende Cache")
            
            conn.close()
            return self.db_path
            
        except Exception as e:
            print(f"‚ö†Ô∏è Fehler bei Datenbank-Initialisierung: {e}")
            print("üóÑÔ∏è Erstelle neue Datenbank...")
            
            # Versuche alte Datei zu l√∂schen und neue zu erstellen
            try:
                if os.path.exists(self.db_path):
                    os.remove(self.db_path)
            except:
                pass
                
            # Rekursiver Aufruf f√ºr neue Datenbank
            return self.init_database()

    def is_file_processed(self, file_info: FileInfo) -> Optional[Tuple[str, str]]:
        """
        Pr√ºft ob eine Datei bereits mit der aktuellen Konfiguration verarbeitet wurde.
        
        Args:
            file_info: FileInfo Objekt mit Datei-Metadaten
        
        Returns:
            Optional[Tuple]: (decision, discard_reasons_json) wenn gefunden, sonst None
        """
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            current_hash = self.get_config_hash()
            
            cursor.execute('''
                SELECT decision, discard_reasons FROM processed_files 
                WHERE file_path = ? AND config_hash = ? AND file_size = ? AND file_mtime = ?
            ''', (file_info.relative_path, current_hash, file_info.size, file_info.mtime))
            
            result = cursor.fetchone()
            conn.close()
            
            return result
        except Exception as e:
            print(f"‚ö†Ô∏è Fehler beim Cache-Zugriff: {e}")
            return None

    def save_file_result(self, file_info: FileInfo, decision: str, discard_reasons: List[str]):
        """
        Speichert das Verarbeitungsergebnis einer Datei in der Datenbank.
        
        Args:
            file_info: FileInfo Objekt mit Datei-Metadaten
            decision: Entscheidung ('kept' oder 'sorted_out')
            discard_reasons: Liste der Gr√ºnde f√ºr Aussortierung
        """
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            current_hash = self.get_config_hash()
            
            # Verwende INSERT OR REPLACE um Duplikate zu vermeiden
            cursor.execute('''
                INSERT OR REPLACE INTO processed_files 
                (file_path, config_hash, file_size, file_mtime, decision, discard_reasons, created_at)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            ''', (file_info.relative_path, current_hash, file_info.size, file_info.mtime, decision, json.dumps(discard_reasons), datetime.now()))
            
            conn.commit()
            conn.close()
        except Exception as e:
            print(f"‚ö†Ô∏è Fehler beim Speichern in Cache: {e}")

    def show_cache_stats(self):
        """
        Zeigt detaillierte Statistiken √ºber den Cache-Inhalt an.
        """
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Anzahl verarbeiteter Dateien
            cursor.execute('SELECT COUNT(*) FROM processed_files')
            total_cached = cursor.fetchone()[0]
            
            # Anzahl nach Entscheidung
            cursor.execute('SELECT decision, COUNT(*) FROM processed_files GROUP BY decision')
            decisions = cursor.fetchall()
            
            # Aktueller Konfigurationshash
            current_hash = self.get_config_hash()
            cursor.execute('SELECT created_at FROM config WHERE config_hash = ?', (current_hash,))
            config_date = cursor.fetchone()
            
            conn.close()
            
            print(f"üóÑÔ∏è Cache-Statistiken:")
            print(f"   üìä Gesamt gecachte Dateien: {total_cached}")
            for decision, count in decisions:
                emoji = "üóëÔ∏è" if decision == "sorted_out" else "üíæ"
                print(f"   {emoji} {decision}: {count}")
            if config_date:
                print(f"   ‚öôÔ∏è Konfiguration erstellt: {config_date[0]}")
            print(f"   üîë Konfigurations-Hash: {current_hash[:8]}...")
            
        except Exception as e:
            print(f"‚ö†Ô∏è Fehler beim Lesen der Cache-Statistiken: {e}")


class ImageAnalyzer:
    """Handles image analysis, YOLO detection, and decision making."""
    
    def __init__(self, model: YOLO):
        self.model = model
    
    def check_image_basic_criteria(self, file_info: FileInfo) -> Tuple[List[str], bool]:
        """
        Pr√ºft Grundkriterien wie Aufl√∂sung und Seitenverh√§ltnis eines Bildes.
        
        Args:
            file_info: FileInfo Objekt mit Bildabmessungen
        
        Returns:
            Tuple[List[str], bool]: (discard_reasons, should_sort_out)
        """
        img_aspect_ratio = file_info.width / file_info.height
        discard_reasons = []
        
        # Pr√ºfe Mindestaufl√∂sung
        if file_info.width < min_resolution[0] or file_info.height < min_resolution[1]:
            discard_reasons.append(f'low_resolution({file_info.width}x{file_info.height})')
            tqdm.write(f"‚ùå Zu kleine Aufl√∂sung aussortiert: {file_info.width}x{file_info.height} < {min_resolution[0]}x{min_resolution[1]}")
            return discard_reasons, True  # should_sort_out = True
        
        # Pr√ºfe Seitenverh√§ltnis
        if abs(img_aspect_ratio - target_aspect_ratio) > aspect_ratio_tolerance:
            discard_reasons.append(f'wrong_aspect_ratio({img_aspect_ratio:.2f})')
            tqdm.write(f"‚ùå Falsches Seitenverh√§ltnis aussortiert: {img_aspect_ratio:.2f} (erwartet: {target_aspect_ratio:.2f} ¬±{aspect_ratio_tolerance})")
            return discard_reasons, True  # should_sort_out = True
        
        return discard_reasons, False  # should_sort_out = False

    def analyze_yolo_detections(self, img, file_info: FileInfo) -> DetectionResult:
        """
        F√ºhrt YOLO-Analyse durch und bestimmt Aktionen basierend auf Erkennungen.
        
        Args:
            img: OpenCV Bild-Array f√ºr YOLO-Analyse
            file_info: FileInfo Objekt mit Datei-Metadaten
        
        Returns:
            DetectionResult: Objekt mit allen Erkennungsdaten und Entscheidungshilfen
        """
        result = DetectionResult()
        
        try:
            yolo_results = self.model.predict(img, device=device, verbose=False)
        except Exception as e:
            tqdm.write(f"‚ùå Fehler bei YOLO-Vorhersage f√ºr {file_info.relative_path}: {e}")
            result.has_error = True
            return result
        
        if len(yolo_results[0].boxes) > 0:
            result.labels = yolo_results[0].boxes.cls.cpu().numpy()
            result.boxes = yolo_results[0].boxes.xyxy.cpu().numpy()
            result.confidences = yolo_results[0].boxes.conf.cpu().numpy()
            
            for i, cls_id in enumerate(result.labels):
                class_name = self.model.names[int(cls_id)]
                confidence = result.confidences[i]
                
                # √úberspringe Erkennungen mit zu niedrigem Confidence-Score
                if confidence < min_confidence_threshold:
                    tqdm.write(f"Erkennung √ºbersprungen: {class_name} (confidence: {confidence:.2f} < {min_confidence_threshold})")
                    continue
                
                # Nur relevante Klassen ber√ºcksichtigen
                if class_name in target_classes:
                    x1, y1, x2, y2 = result.boxes[i]
                    object_area = (x2 - x1) * (y2 - y1)
                    
                    if object_area >= large_area_threshold and confidence >= max_confidence_threshold:
                        # Gro√ües Objekt UND hohe Confidence ‚Üí automatisch aussortieren
                        result.discard_reasons.append(f'{class_name}(area:{int(object_area)},conf:{confidence:.2f})')
                        tqdm.write(f"üîí Gro√üe {class_name} mit hoher Confidence aussortiert: area={int(object_area)}, conf={confidence:.2f}")
                    elif object_area <= small_area_threshold:
                        # Kleines Objekt ‚Üí automatisch behalten
                        tqdm.write(f"‚úÖ Kleine {class_name} behalten: area={int(object_area)}, conf={confidence:.2f}")
                    elif confidence <= min_confidence_threshold:
                        # Niedrige Confidence ‚Üí automatisch behalten
                        tqdm.write(f"‚úÖ {class_name} behalten (niedrige Confidence): area={int(object_area)}, conf={confidence:.2f}")
                    else:
                        # Mittlere Confidence ODER mittlere Gr√∂√üe ‚Üí nachfragen
                        result.needs_manual_decision = True
                        tqdm.write(f"ü§î {class_name} - Entscheidung n√∂tig: area={int(object_area)}, conf={confidence:.2f}")
        
        return result

    def show_decision_gui(self, img, detection_result: DetectionResult, filename: str) -> bool:
        """
        Zeigt eine grafische Benutzeroberfl√§che f√ºr manuelle Entscheidungen bei unsicheren Erkennungen.
        
        Args:
            img: OpenCV Bild-Array f√ºr die Anzeige
            detection_result: DetectionResult Objekt mit YOLO-Erkennungen
            filename: Name der Datei f√ºr Fenstertitel
        
        Returns:
            bool: True wenn Benutzer "BEHALTEN" w√§hlt, False bei "AUSSORTIEREN"
        """
        
        # Filtere nur unsichere Erkennungen f√ºr die Anzeige
        uncertain_indices = []
        if detection_result.boxes is not None:
            for i, cls_id in enumerate(detection_result.labels):
                class_name = self.model.names[int(cls_id)]
                confidence = detection_result.confidences[i]
                x1, y1, x2, y2 = detection_result.boxes[i]
                object_area = (x2 - x1) * (y2 - y1)
                
                # Filtere Objekte, die eine manuelle Entscheidung ben√∂tigen
                if (class_name in target_classes and 
                    confidence >= min_confidence_threshold and
                    ((min_confidence_threshold <= confidence < max_confidence_threshold) or 
                     (small_area_threshold < object_area < large_area_threshold))):
                    uncertain_indices.append(i)
        
        # Zeichne nur unsichere Bounding Boxes auf das Bild
        img_display = img.copy()
        if detection_result.boxes is not None:
            for i in uncertain_indices:
                x1, y1, x2, y2 = detection_result.boxes[i].astype(int)
                confidence = detection_result.confidences[i]
                class_name = self.model.names[int(detection_result.labels[i])]
                area = (x2 - x1) * (y2 - y1)
                
                # Orange f√ºr unsichere Objekte
                color = (0, 127, 255)  # Orange
                    
                cv2.rectangle(img_display, (x1, y1), (x2, y2), color, 2)
                cv2.putText(img_display, f'{class_name} ({int(area)}) {confidence:.2f}', 
                           (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
        
        # Tkinter GUI erstellen
        root = tk.Tk()
        root.title(f"Entscheidung f√ºr: {filename}")
        
        # Maximiere das Fenster oder verwende 90% der Bildschirmgr√∂√üe
        screen_width = root.winfo_screenwidth()
        screen_height = root.winfo_screenheight()
        window_width = int(screen_width * 0.9)
        window_height = int(screen_height * 0.9)
        
        root.geometry(f"{window_width}x{window_height}")
        
        # Bild f√ºr Tkinter vorbereiten
        img_rgb = cv2.cvtColor(img_display, cv2.COLOR_BGR2RGB)
        img_pil_original = Image.fromarray(img_rgb)  # Original f√ºr Resize speichern
        
        # GUI Elemente
        label = tk.Label(root)
        label.pack(pady=10, expand=True, fill='both')
        
        # Variable f√ºr Resize-Timer
        resize_timer = None
        last_size = (0, 0)
        
        def resize_image():
            """Passt das Bild an die aktuelle Fenstergr√∂√üe an"""
            try:
                # Aktuelle Fenstergr√∂√üe ermitteln
                current_width = root.winfo_width()
                current_height = root.winfo_height()
                
                # Nur resize wenn sich die Gr√∂√üe signifikant ge√§ndert hat
                nonlocal last_size
                if abs(current_width - last_size[0]) < 10 and abs(current_height - last_size[1]) < 10:
                    return
                
                last_size = (current_width, current_height)
                
                # Verf√ºgbaren Platz berechnen
                available_width = current_width - 40
                available_height = current_height - 150
                
                if available_width > 50 and available_height > 50:  # Mindestgr√∂√üe
                    # Skalierung berechnen
                    img_aspect = img_pil_original.width / img_pil_original.height
                    
                    if available_width / img_aspect <= available_height:
                        new_width = available_width
                        new_height = int(available_width / img_aspect)
                    else:
                        new_height = available_height
                        new_width = int(available_height * img_aspect)
                    
                    # Bild skalieren und anzeigen
                    resized_img = img_pil_original.resize((new_width, new_height), Image.Resampling.LANCZOS)
                    img_tk = ImageTk.PhotoImage(resized_img)
                    label.configure(image=img_tk)
                    label.image = img_tk  # Referenz behalten
            except Exception as e:
                print(f"Resize error: {e}")  # Debug-Info
        
        def on_window_resize(event):
            """Handler f√ºr Fenstergr√∂√üen√§nderungen mit Timer"""
            nonlocal resize_timer
            if resize_timer:
                root.after_cancel(resize_timer)
            # Warte 100ms nach letzter √Ñnderung bevor resize
            resize_timer = root.after(100, resize_image)
        
        info_text = tk.Label(root, text=f"Datei: {filename}\nOrange=manuelle Entscheidung n√∂tig\nZahlen: (Fl√§che) Confidence-Score\n\nAngezeigt: mittlere Confidence ({min_confidence_threshold:.2f}-{max_confidence_threshold:.2f}) oder mittlere Objektgr√∂√üe ({small_area_threshold//1000}k-{large_area_threshold//1000}k)", 
                            font=("Arial", 10))
        info_text.pack(pady=5)
        
        result = {'keep': False}
        
        def on_window_close():
            """Handler f√ºr das Schlie√üen des Fensters √ºber X - beendet das gesamte Skript"""
            tqdm.write("\nüõë Skript durch Benutzer beendet - aktuelle Datei wird nicht verschoben")
            root.destroy()
            exit(0)  # Beendet das gesamte Skript sofort
        
        def keep_file():
            result['keep'] = True
            root.destroy()
        
        def skip_file():
            result['keep'] = False
            root.destroy()
        
        # Event-Handler nur f√ºr das Root-Fenster
        root.bind('<Configure>', lambda e: on_window_resize(e) if e.widget == root else None)
        
        # Handler f√ºr das Schlie√üen des Fensters √ºber X
        root.protocol("WM_DELETE_WINDOW", on_window_close)
        
        # Initiales Resize nach kurzer Verz√∂gerung
        root.after(200, resize_image)
        
        # Buttons
        button_frame = tk.Frame(root)
        button_frame.pack(pady=10)
        
        keep_btn = tk.Button(button_frame, text="BEHALTEN (nicht verschieben)", 
                            command=keep_file, bg="lightgreen", font=("Arial", 12))
        keep_btn.pack(side=tk.LEFT, padx=10)
        
        skip_btn = tk.Button(button_frame, text="AUSSORTIEREN", 
                            command=skip_file, bg="lightcoral", font=("Arial", 12))
        skip_btn.pack(side=tk.LEFT, padx=10)
        
        # Fenster zentrieren
        root.update_idletasks()
        x = (root.winfo_screenwidth() // 2) - (root.winfo_width() // 2)
        y = (root.winfo_screenheight() // 2) - (root.winfo_height() // 2)
        root.geometry(f"+{x}+{y}")
        
        root.mainloop()
        return result['keep']

    def make_decision(self, basic_discard_reasons: List[str], detection_result: DetectionResult, img, file_info: FileInfo, stats: ProcessingStats) -> Tuple[bool, List[str]]:
        """
        Trifft die endg√ºltige Entscheidung basierend auf Analyse-Ergebnissen.
        
        Args:
            basic_discard_reasons: Bereits gefundene Gr√ºnde f√ºr Aussortierung (aus Grundkriterien)
            detection_result: DetectionResult mit YOLO-Erkennungen
            img: OpenCV Bild-Array f√ºr GUI-Anzeige
            file_info: FileInfo Objekt mit Datei-Metadaten
            stats: ProcessingStats Objekt das aktualisiert wird
        
        Returns:
            Tuple[bool, List[str]]: (should_sort_out, all_discard_reasons)
        """
        should_sort_out = False
        all_discard_reasons = basic_discard_reasons + detection_result.discard_reasons
        
        if detection_result.discard_reasons:
            # Sichere Erkennung vorhanden - automatisch aussortieren
            should_sort_out = True
            stats.auto_sorted += 1
            tqdm.write(f"üîí Automatisches Aussortieren wegen sicherer Erkennung: {detection_result.discard_reasons}")
        elif detection_result.needs_manual_decision:
            # Nur unsichere Erkennungen - GUI f√ºr manuelle Entscheidung zeigen
            stats.manual_decisions += 1
            user_wants_to_keep = self.show_decision_gui(img, detection_result, file_info.relative_path)
            should_sort_out = not user_wants_to_keep
            if should_sort_out:
                stats.manual_sorted += 1
                all_discard_reasons.append('manual_decision_sort_out')
        
        return should_sort_out, all_discard_reasons


class FileProcessor:
    """Handles file processing, movement, and orchestrates the entire processing workflow."""
    
    def __init__(self, db_manager: DatabaseManager, image_analyzer: ImageAnalyzer):
        self.db_manager = db_manager
        self.image_analyzer = image_analyzer
    
    def process_file_movement(self, should_sort_out: bool, file_info: FileInfo, target_folder: str, discard_reasons: List[str], from_cache: bool, needs_manual_decision: bool, stats: ProcessingStats):
        """
        Verarbeitet das Verschieben oder Behalten von Dateien basierend auf der Entscheidung.
        
        Args:
            should_sort_out: True wenn Datei aussortiert werden soll
            file_info: FileInfo Objekt mit Datei-Metadaten
            target_folder: Zielordner f√ºr aussortierte Dateien
            discard_reasons: Gr√ºnde f√ºr die Aussortierung
            from_cache: True wenn Entscheidung aus Cache stammt
            needs_manual_decision: True wenn manuelle Entscheidung getroffen wurde
            stats: ProcessingStats Objekt das aktualisiert wird
        """
        if should_sort_out:
            # Verschiebe unerw√ºnschte Bilder in den Aussortier-Ordner
            target_path = os.path.join(target_folder, file_info.relative_path)
            os.makedirs(os.path.dirname(target_path), exist_ok=True)
            
            try:
                shutil.move(file_info.absolute_path, target_path)
                file_uri = f"file://{target_path.replace(' ', '%20')}"
                
                if from_cache:
                    tqdm.write(f"üîÑ {file_info.relative_path} erneut aussortiert (Cache)")
                    stats.auto_sorted += 1
                else:
                    tqdm.write(f"üóëÔ∏è {file_info.relative_path} aussortiert (gefunden: {discard_reasons})")
                    tqdm.write(f"üìÅ {file_uri}")
                    tqdm.write("")
            except Exception as e:
                tqdm.write(f"‚ùå Fehler beim Verschieben von {file_info.relative_path}: {e}")
                stats.errors += 1
                tqdm.write("")
        else:
            # Datei behalten
            if not from_cache:
                if needs_manual_decision:
                    tqdm.write(f"‚úÖ {file_info.relative_path} behalten (manuelle Entscheidung)")
                else:
                    tqdm.write(f"‚úÖ {file_info.relative_path} behalten (keine relevanten Objekte erkannt)")
                stats.kept_files += 1

    def process_single_image(self, root: str, filename: str, context: ProcessingContext):
        """
        Verarbeitet eine einzelne Bilddatei komplett von Cache-Pr√ºfung bis zur finalen Entscheidung.
        
        Args:
            root: Wurzelverzeichnis in dem sich die Datei befindet
            filename: Name der Bilddatei
            context: ProcessingContext mit allen notwendigen Verarbeitungsparametern
        """
        # FileInfo Objekt erstellen
        file_info = FileInfo(
            relative_path=os.path.relpath(os.path.join(root, filename), context.source_folder),
            absolute_path=os.path.join(root, filename),
            size=0,
            mtime=0
        )
        
        # Progress Bar Update
        context.pbar.set_postfix({
            'Aktuell': file_info.relative_path[:30] + '...' if len(file_info.relative_path) > 30 else file_info.relative_path,
            'Cache': context.stats.cached_files,
            'Aussortiert': context.stats.auto_sorted,
            'Entscheidungen': context.stats.manual_decisions
        })
        
        # === CACHE-PR√úFUNG ===
        try:
            file_stat = os.stat(file_info.absolute_path)
            file_info.size = file_stat.st_size
            file_info.mtime = file_stat.st_mtime
            
            cached_result = self.db_manager.is_file_processed(file_info)
            if cached_result:
                decision, discard_reasons_json = cached_result
                discard_reasons = json.loads(discard_reasons_json) if discard_reasons_json else []
                
                context.stats.cached_files += 1
                should_sort_out = (decision == 'sorted_out')
                
                if should_sort_out:
                    tqdm.write(f"üîÑ {file_info.relative_path} wird aussortiert (Cache)")
                else:
                    tqdm.write(f"üíæ {file_info.relative_path} behalten (Cache)")
                    context.stats.kept_files += 1
                    return  # Fr√ºhes Return f√ºr gecachte "behalten" Entscheidungen
                
                # Verarbeite gecachte "aussortieren" Entscheidung
                self.process_file_movement(should_sort_out, file_info, context.target_folder, discard_reasons, True, False, context.stats)
                return
                
        except Exception as e:
            tqdm.write(f"‚ö†Ô∏è Cache-Fehler f√ºr {file_info.relative_path}: {e}")
        
        # === NEUE VERARBEITUNG ===
        img = cv2.imread(file_info.absolute_path)
        if img is None:
            tqdm.write(f"‚ö†Ô∏è Kann {file_info.relative_path} nicht laden - √ºberspringe")
            context.stats.errors += 1
            return
        
        context.stats.processed_files += 1
        img_height, img_width = img.shape[:2]
        file_info.width = img_width
        file_info.height = img_height
        
        # Pr√ºfe Grundkriterien (Aufl√∂sung, Seitenverh√§ltnis)
        basic_discard_reasons, should_sort_out = self.image_analyzer.check_image_basic_criteria(file_info)
        
        if should_sort_out:
            # Grundkriterien nicht erf√ºllt - direktes Aussortieren
            context.stats.auto_sorted += 1
            self.process_file_movement(should_sort_out, file_info, context.target_folder, basic_discard_reasons, False, False, context.stats)
            self.db_manager.save_file_result(file_info, 'sorted_out', basic_discard_reasons)
            return
        
        # YOLO-Analyse durchf√ºhren
        detection_result = self.image_analyzer.analyze_yolo_detections(img, file_info)
        
        if detection_result.has_error:
            context.stats.errors += 1
            return
        
        # Entscheidung treffen
        should_sort_out, all_discard_reasons = self.image_analyzer.make_decision(basic_discard_reasons, detection_result, img, file_info, context.stats)
        
        # Datei verarbeiten (verschieben oder behalten)
        self.process_file_movement(should_sort_out, file_info, context.target_folder, all_discard_reasons, False, detection_result.needs_manual_decision, context.stats)
        
        # Ergebnis in Datenbank speichern
        decision = 'sorted_out' if should_sort_out else 'kept'
        self.db_manager.save_file_result(file_info, decision, all_discard_reasons)


# === Legacy Functions (kept for compatibility) ===
def get_config_hash():
    """Legacy function - use DatabaseManager.get_config_hash() instead"""
    db_manager = DatabaseManager(source_folder)
    return db_manager.get_config_hash()

def init_database():
    """Legacy function - use DatabaseManager.init_database() instead"""
    db_manager = DatabaseManager(source_folder)
    return db_manager.init_database()

def is_file_processed(db_path: str, file_info: FileInfo) -> Optional[Tuple[str, str]]:
    """Legacy function - use DatabaseManager.is_file_processed() instead"""
    db_manager = DatabaseManager(source_folder)
    return db_manager.is_file_processed(file_info)

def save_file_result(db_path: str, file_info: FileInfo, decision: str, discard_reasons: List[str]):
    """Legacy function - use DatabaseManager.save_file_result() instead"""
    db_manager = DatabaseManager(source_folder)
    return db_manager.save_file_result(file_info, decision, discard_reasons)

def show_cache_stats(db_path):
    """Legacy function - use DatabaseManager.show_cache_stats() instead"""
    db_manager = DatabaseManager(source_folder)
    return db_manager.show_cache_stats()

def check_image_basic_criteria(file_info: FileInfo) -> Tuple[List[str], bool]:
    """Legacy function - use ImageAnalyzer.check_image_basic_criteria() instead"""
    analyzer = ImageAnalyzer(model)
    return analyzer.check_image_basic_criteria(file_info)

def analyze_yolo_detections(img, file_info: FileInfo) -> DetectionResult:
    """Legacy function - use ImageAnalyzer.analyze_yolo_detections() instead"""
    analyzer = ImageAnalyzer(model)
    return analyzer.analyze_yolo_detections(img, file_info)

def make_decision(basic_discard_reasons: List[str], detection_result: DetectionResult, img, file_info: FileInfo, stats: ProcessingStats) -> Tuple[bool, List[str]]:
    """Legacy function - use ImageAnalyzer.make_decision() instead"""
    analyzer = ImageAnalyzer(model)
    return analyzer.make_decision(basic_discard_reasons, detection_result, img, file_info, stats)

def process_file_movement(should_sort_out: bool, file_info: FileInfo, target_folder: str, discard_reasons: List[str], from_cache: bool, needs_manual_decision: bool, stats: ProcessingStats):
    """Legacy function - use FileProcessor.process_file_movement() instead"""
    db_manager = DatabaseManager(source_folder)
    analyzer = ImageAnalyzer(model)
    processor = FileProcessor(db_manager, analyzer)
    return processor.process_file_movement(should_sort_out, file_info, target_folder, discard_reasons, from_cache, needs_manual_decision, stats)

def process_single_image(root: str, filename: str, context: ProcessingContext):
    """Legacy function - use FileProcessor.process_single_image() instead"""
    db_manager = DatabaseManager(source_folder)
    analyzer = ImageAnalyzer(model)
    processor = FileProcessor(db_manager, analyzer)
    return processor.process_single_image(root, filename, context)

def main():
    """
    Hauptfunktion f√ºr die Bildverarbeitung und -sortierung.
    
    Orchestriert den gesamten Workflow mit vereinfachten Datenstrukturen:
    1. Initialisiert Zielordner und Datenbank
    2. Sammelt alle unterst√ºtzten Bilddateien aus dem Quellordner
    3. Verarbeitet jede Datei einzeln mit Cache-Optimierung
    4. Zeigt finale Statistiken an
    """
    # === Aussortier-Ordner anlegen ===
    os.makedirs(target_folder, exist_ok=True)

    # === Initialisiere Class-basierte Komponenten ===
    print("ü§ñ Lade YOLO-Modell...")
    global model
    model = YOLO("yolov8s.pt")
    
    print("üóÑÔ∏è Initialisiere Datenbank...")
    db_manager = DatabaseManager(source_folder)
    db_path = db_manager.init_database()
    db_manager.show_cache_stats()
    
    # Erstelle Analyzer und Processor
    image_analyzer = ImageAnalyzer(model)
    file_processor = FileProcessor(db_manager, image_analyzer)

    # === Statistiken ===
    stats = ProcessingStats()

    print(f"üîç Durchsuche Ordner: {source_folder}")
    print(f"üìÅ Aussortier-Ordner: {target_folder}")
    print(f"üéØ Suche nach: {', '.join(target_classes)}")
    print("=" * 60)

    # === Sammle alle Bilddateien ===
    print("üìä Sammle Bilddateien...")
    all_image_files = []
    for root, dirs, files in os.walk(source_folder):
        for filename in files:
            if filename.lower().endswith(CONFIG['supported_extensions']):
                all_image_files.append((root, filename))

    print(f"‚úÖ {len(all_image_files)} Bilddateien gefunden")
    print("=" * 60)

    # === Bilder durchgehen mit Progress Bar ===
    with tqdm(total=len(all_image_files), desc="üñºÔ∏è Verarbeite Bilder", unit="Bild") as pbar:
        # ProcessingContext erstellen
        context = ProcessingContext(
            source_folder=source_folder,
            target_folder=target_folder,
            db_path=db_path,
            stats=stats,
            pbar=pbar
        )
        
        for root, filename in all_image_files:
            stats.total_files += 1
            
            # Verarbeite einzelne Datei mit Class-basiertem Processor
            file_processor.process_single_image(root, filename, context)
            
            # Progress Bar Update
            pbar.update(1)

    # === Abschluss-Statistik ===
    print("\n" + "=" * 60)
    print("üìä VERARBEITUNGSSTATISTIK")
    print("=" * 60)
    print(f"üìÅ Gefundene Dateien: {stats.total_files}")
    print(f"üóÑÔ∏è Aus Cache geladen: {stats.cached_files}")
    print(f"‚úÖ Neu verarbeitet: {stats.processed_files}")
    print(f"üîí Automatisch aussortiert: {stats.auto_sorted}")
    print(f"ü§î Manuelle Entscheidungen: {stats.manual_decisions}")
    print(f"   ‚îî‚îÄ üóëÔ∏è Manuell aussortiert: {stats.manual_sorted}")
    print(f"   ‚îî‚îÄ üíæ Manuell behalten: {stats.manual_decisions - stats.manual_sorted}")
    print(f"üíæ Behalten gesamt: {stats.kept_files}")
    print(f"‚ùå Fehler: {stats.errors}")
    print(f"üóëÔ∏è Aussortiert gesamt: {stats.auto_sorted + stats.manual_sorted}")
    print("=" * 60)
    print(f"üíæ Cache-Datei: {os.path.join(source_folder, '.image_filter_cache.db')}")
    print("‚ú® Verarbeitung abgeschlossen!")

if __name__ == "__main__":
    main()
